# 58同城职位信息爬虫

一个功能强大的58同城招聘信息爬虫工具，支持多城市、多页面批量抓取，具备智能数据清洗和实时保存功能。

## 🚀 功能特性

### 核心功能
- **多城市支持**：支持北京、上海、广州、深圳、成都、西安、郑州等7个主要城市
- **批量抓取**：每个城市自动抓取前5页职位信息
- **实时保存**：每抓取一个职位立即保存到Excel和JSON文件
- **智能去重**：自动过滤重复职位信息
- **数据清洗**：智能清理无效和不规范的数据

## 数据字段

本工具抓取的职位信息包含以下字段：

### 企业信息
- 企业名称
- 企业类型（智能标准化）
- 社会信用码
- 企业规模（智能标准化）
- 注册资本(万)
- 所属区域（智能清洗后的标准格式）
- 联系人
- 联系方式
- 联系邮箱
- 办公地址
- 企业简介
- 营业执照
- 企业相册

### 职位信息
- 岗位名称
- 薪资类型
- 薪资范围起
- 薪资范围至
- 工作地点
- 岗位要求
- 学历要求
- 招聘人数
- 发布时间
- 结束时间
- 工作职责
- 任职要求

## 字段匹配规则详解

### 薪资信息提取
**匹配模式：**
- `(\d+)[-~](\d+)元/月` - 月薪范围
- `(\d+)[-~](\d+)万/年` - 年薪范围
- `(\d+)[-~](\d+)千/月` - 千元月薪
- `薪资.*?(\d+)[-~](\d+)` - 通用薪资模式
- `工资.*?(\d+)[-~](\d+)` - 工资关键词模式

**处理逻辑：**
- 优先从CSS选择器提取
- 如果未找到，使用正则表达式从页面前30行文本中提取
- 薪资类型：有范围值时为"非面谈"，否则为"面谈"

### 工作地点提取
**匹配模式：**
- `(北京)\s*[-\s]*([\u4e00-\u9fa5]+区)` - 北京地区
- `(上海)\s*[-\s]*([\u4e00-\u9fa5]+区)` - 上海地区
- `(广州)\s*[-\s]*([\u4e00-\u9fa5]+区)` - 广州地区
- `(深圳)\s*[-\s]*([\u4e00-\u9fa5]+区)` - 深圳地区
- `([\u4e00-\u9fa5]+市?)\s*[-\s]*([\u4e00-\u9fa5]+区)` - 通用城市区域

**输出格式：** "城市 - 区域"（如：北京 - 朝阳区）

### 学历要求提取
**匹配模式：**
- `学历要求.*?(博士|硕士|研究生|本科|大专|专科|高中|中专|初中|不限)`
- `学历.*?(博士|硕士|研究生|本科|大专|专科|高中|中专|初中|不限)`
- `(博士|硕士|研究生|本科|大专|专科)以上`
- `要求.*?(博士|硕士|研究生|本科|大专|专科|高中|中专|初中)`

**处理逻辑：**
- 初中、中专、高中统一显示为"学历不限"
- 优先从CSS选择器`.item_condition`提取
- 备用正则表达式从页面前50行提取

### 工作经验要求提取
**匹配模式：**
- `工作经验.*?(\d+)[-~](\d+)年`
- `经验.*?(\d+)[-~](\d+)年`
- `(\d+)年以上.*?经验`
- `经验.*?(\d+)年以上`
- `(无需经验|不限经验|应届毕业生|经验不限)`

**处理逻辑：**
- 优先从CSS选择器提取，排除包含"学历"和"招"的文本
- 备用正则表达式从页面前50行提取

### 招聘人数提取
**匹配模式：**
- `招聘.*?(\d+)人`
- `招.*?(\d+)人`
- `(\d+)人`

**处理逻辑：**
- 默认值为1
- 优先从CSS选择器`.item_condition`中包含"招"和"人"的文本提取
- 备用正则表达式从页面前40行提取
- 输出为数字类型

### 发布时间提取
**匹配模式：**
- `发布时间.*?(\d{4}-\d{2}-\d{2})` - 完整日期
- `(\d{4}-\d{2}-\d{2})` - 标准日期格式
- `(\d{2}-\d{2})` - 月日格式
- `(今天|昨天|前天)` - 相对时间
- `(\d+)小时前` - 小时前
- `(\d+)天前` - 天前

### 工作职责提取
**匹配模式：**
- `岗位职责[：:]?\s*(.*?)(?=任职要求|福利待遇|联系方式|$)`
- `工作职责[：:]?\s*(.*?)(?=任职要求|福利待遇|联系方式|$)`
- `工作内容[：:]?\s*(.*?)(?=任职要求|福利待遇|联系方式|$)`

**备用规则：**
- `岗位职责[：:]?\s*([\s\S]*?)(?=任职要求|职位要求|岗位要求|$)`
- `工作职责[：:]?\s*([\s\S]*?)(?=任职要求|职位要求|岗位要求|$)`
- `工作内容[：:]?\s*([\s\S]*?)(?=任职要求|职位要求|岗位要求|$)`

**处理逻辑：**
- 优先从`.des`职位描述区域提取
- 限制长度为500字符
- 去除开头的】符号

### 任职要求提取
**匹配模式：**
- `任职要求[：:]?\s*(.*?)(?=福利待遇|联系方式|$)`
- `职位要求[：:]?\s*(.*?)(?=福利待遇|联系方式|$)`
- `岗位要求[：:]?\s*(.*?)(?=福利待遇|联系方式|$)`

**备用规则：**
- `任职要求[：:]?\s*([\s\S]*?)(?=福利待遇|联系方式|$)`
- `职位要求[：:]?\s*([\s\S]*?)(?=福利待遇|联系方式|$)`
- `岗位要求[：:]?\s*([\s\S]*?)(?=福利待遇|联系方式|$)`

**处理逻辑：**
- 优先从`.des`职位描述区域提取
- 限制长度为500字符
- 去除开头的】符号

### 联系方式提取
**匹配模式：**
- `联系电话.*?(1[3-9]\d{9})` - 联系电话关键词
- `电话.*?(1[3-9]\d{9})` - 电话关键词
- `手机.*?(1[3-9]\d{9})` - 手机关键词
- `(1[3-9]\d{9})` - 通用手机号格式

### 邮箱提取
**匹配模式：**
- `([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})` - 标准邮箱格式

### 办公地址提取
**匹配模式：**
- `办公地址.*?([\u4e00-\u9fa5]+市[\u4e00-\u9fa5]+区.*?)(?=联系|电话|邮箱|$)`
- `地址.*?([\u4e00-\u9fa5]+市[\u4e00-\u9fa5]+区.*?)(?=联系|电话|邮箱|$)`
- `公司地址.*?([\u4e00-\u9fa5]+市[\u4e00-\u9fa5]+区.*?)(?=联系|电话|邮箱|$)`

**处理逻辑：**
- 限制长度为100字符
- 只保留包含市区信息的地址

### 智能数据处理

#### 所属区域智能清洗

**清洗规则：**
- 去除"总部位于"等前缀
- 统一格式为"XX省XX市XX区"或"XX市XX区"
- 过滤包含无关词汇的内容
- 如果所属区域为空，会从工作地点自动补充

**过滤的无关词汇：**
```
找工作、免费发布、登记简历、公司福利、饭补、加班补助、
交通便利、餐补、市中心区、不匹配、人公司、福利、补助、便利、
有限公司、科技有限公司、信息科技、华南地区、华北地区、华东地区、
华西地区、在华、地区、公司在
```

**匹配模式：**
- `([\u4e00-\u9fa5]{2,4}省[\u4e00-\u9fa5]{2,4}市[\u4e00-\u9fa5]{2,4}区)` - 省市区格式
- `([\u4e00-\u9fa5]{2,4}市[\u4e00-\u9fa5]{2,4}区)` - 市区格式

**处理逻辑：**
- 长度限制：≤10个字符
- 包含无关词汇时清空该字段
- 不符合标准格式时清空该字段

#### 薪资信息标准化

**支持的薪资格式：**
- 月薪："5000-8000元/月"
- 年薪："10-15万/年"
- 千元："5-8千/月"
- 面谈："薪资面谈"、"待遇面议"

**处理逻辑：**
- 自动计算薪资范围的起始和结束值
- 智能判断薪资类型（面谈/非面谈）
- 年薪自动转换为月薪（除以12）
- 千元格式自动转换为元（乘以1000）

#### 企业规模标准化

**标准化规则：**
- "1-49人" → "小型企业(1-49人)"
- "50-99人" → "小型企业(50-99人)"
- "100-499人" → "中型企业(100-499人)"
- "500-999人" → "中型企业(500-999人)"
- "1000人以上" → "大型企业(1000人以上)"

**匹配模式：**
- `(\d+)[-~](\d+)人` - 范围格式
- `(\d+)人以上` - 以上格式
- `(\d+)人以下` - 以下格式

#### 企业类型标准化

**标准化规则：**
- 互联网相关 → "互联网/通信"
- 金融相关 → "金融/投资"
- 教育相关 → "教育/培训"
- 制造相关 → "制造/生产"
- 贸易相关 → "贸易/零售"
- 服务相关 → "服务业"
- 其他 → "其他"

**关键词匹配：**
```python
# 互联网/通信
['互联网', '网络', '软件', '科技', '信息技术', 'IT', '通信', '电子商务', '游戏']

# 金融/投资
['金融', '银行', '保险', '证券', '投资', '基金', '信贷', '财务']

# 教育/培训
['教育', '培训', '学校', '大学', '学院', '幼儿园', '早教']

# 制造/生产
['制造', '生产', '工厂', '机械', '汽车', '电子', '化工', '纺织']

# 贸易/零售
['贸易', '零售', '批发', '商贸', '超市', '商场', '电商']

# 服务业
['服务', '咨询', '物流', '餐饮', '酒店', '旅游', '医疗', '房地产']
```

## 数据质量控制

### 数据过滤规则
**过滤条件（满足任一条件将被过滤）：**
- 企业名称为空或无效
- 工作职责为空
- 任职要求为空
- 岗位名称包含无关内容（如"兼职"、"代理"等）

### 数据验证规则
**必填字段验证：**
- 企业名称：长度 > 0
- 岗位名称：长度 > 0
- 工作职责：长度 > 10
- 任职要求：长度 > 10

**数据格式验证：**
- 薪资范围：必须为数字类型
- 招聘人数：必须为正整数
- 联系方式：必须符合手机号格式
- 邮箱：必须符合邮箱格式

### 重复数据处理
**去重策略：**
- 基于企业名称 + 岗位名称进行去重
- 保留最新抓取的数据
- 记录重复数据统计信息

### 异常数据处理
**异常情况处理：**
- 页面加载超时：记录日志，跳过该职位
- 验证码出现：自动刷新页面重试
- 反爬虫检测：随机延时后重试
- 数据解析失败：使用备用解析规则

## 📋 系统要求

### 环境依赖
- Python 3.7+
- Chrome浏览器
- ChromeDriver（自动管理）

### 必需库
```
selenium>=4.0.0
beautifulsoup4>=4.9.0
pandas>=1.3.0
requests>=2.25.0
webdriver-manager>=3.8.0
openpyxl>=3.0.0
```

## 🛠️ 安装与配置

### 1. 克隆项目
```bash
git clone <repository-url>
cd 58同城抓取数据
```

### 2. 创建虚拟环境
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac
```

### 3. 安装依赖
```bash
pip install -r requirements.txt
```

### 4. 运行脚本
```bash
python enhanced_job_scraper.py
```

## 📖 使用示例

### 字段匹配示例

**薪资信息提取示例：**
```
原始文本："薪资待遇：8000-12000元/月"
匹配结果：
- 薪资范围起：8000
- 薪资范围至：12000
- 薪资类型：非面谈
```

**工作地点提取示例：**
```
原始文本："工作地点：北京朝阳区"
匹配结果："北京 - 朝阳区"
```

**学历要求提取示例：**
```
原始文本："学历要求：本科及以上"
匹配结果："本科"

原始文本："高中学历即可"
匹配结果："学历不限"
```

**工作职责提取示例：**
```
原始文本："岗位职责：1.负责产品设计；2.参与需求分析"
匹配结果："1.负责产品设计；2.参与需求分析"
```

### 数据清洗示例

**所属区域清洗示例：**
```
原始数据："总部位于北京市朝阳区"
清洗结果："北京市朝阳区"

原始数据："找工作就来我们公司"
清洗结果：""（被过滤）
```

**企业类型标准化示例：**
```
原始数据："互联网科技公司"
标准化结果："互联网/通信"

原始数据："教育培训机构"
标准化结果："教育/培训"
```

## 📊 输出文件

### 主要输出
- `58同城多城市职位详细信息.xlsx` - Excel格式的职位数据
- `58同城多城市职位详细信息.json` - JSON格式的职位数据备份

### 辅助工具
- `other/clean_region_enhanced.py` - 数据清洗脚本
- `other/data_comparison.py` - Excel与JSON数据一致性检查
- `other/check_json_count.py` - 数据统计工具

## 🔧 技术架构

### 核心类：Enhanced58JobScraper

#### 主要方法
1. **`__init__(headless=True)`** - 初始化爬虫，配置Chrome选项
2. **`scrape_multiple_pages(base_url, max_pages=5)`** - 批量抓取多页数据
3. **`get_job_list_from_page(url)`** - 抓取单页职位列表
4. **`scrape_job_detail_page(job_url)`** - 抓取职位详情
5. **`scrape_company_detail_page(company_url)`** - 抓取企业详情
6. **`save_single_job_to_excel(job_data, filename)`** - 实时保存单个职位
7. **`save_to_excel(data, filename)`** - 批量保存数据

### 数据处理流程
```
城市URL列表 → 生成页面URL → 抓取职位链接 → 抓取职位详情 → 数据清洗 → 实时保存
```

### 反爬虫策略
- **请求间隔**：页面间延时1秒，职位间延时0.5秒
- **浏览器伪装**：禁用自动化检测特征
- **验证码处理**：自动检测并提示手动处理
- **错误重试**：网络异常自动重试机制

## ⚙️ 配置选项

### 城市配置
在`main()`函数中修改`city_urls`字典来添加或删除城市：
```python
city_urls = {
    "北京": ["https://bj.58.com/hulianwangtx/"],
    "上海": ["https://sh.58.com/hulianwangtx/"],
    # 添加更多城市...
}
```

### 抓取页数
修改`max_pages`参数来调整每个城市的抓取页数：
```python
city_data = scraper.scrape_multiple_pages(base_url, max_pages=5)
```

### 浏览器模式
```python
# 无头模式（后台运行）
scraper = Enhanced58JobScraper(headless=True)

# 可视模式（显示浏览器）
scraper = Enhanced58JobScraper(headless=False)
```

## 📈 性能优化

### Chrome优化选项
- 禁用图片加载
- 禁用GPU渲染
- 禁用插件和扩展
- 减少日志输出
- 优化内存使用

### 数据处理优化
- 实时保存避免内存溢出
- 智能过滤减少无效数据
- 批量操作提高效率

## 🚨 注意事项

### 使用限制
1. **遵守robots.txt**：请遵守网站的爬虫协议
2. **合理频率**：避免过于频繁的请求
3. **数据用途**：仅用于学习和研究目的
4. **法律合规**：确保符合相关法律法规

### 常见问题

#### 验证码问题
- 脚本会自动检测验证码页面
- 出现验证码时会暂停并提示手动处理
- 完成验证后按回车继续执行

#### 数据质量
- 所属区域为空的职位会被跳过
- 企业名称、工作职责、任职要求为空的职位会被过滤
- 重复职位会被自动去重

#### 网络异常
- 脚本具备基本的错误处理机制
- 单个职位失败不会影响整体抓取
- 建议在网络稳定的环境下运行

## 📝 更新日志

### v2.0 (当前版本)
- ✅ 增强所属区域智能清洗功能
- ✅ 添加更多无关词汇过滤
- ✅ 优化正则表达式匹配
- ✅ 改进数据验证逻辑
- ✅ 修复缩进错误

### v1.0
- ✅ 基础多城市抓取功能
- ✅ 实时数据保存
- ✅ Excel和JSON双格式输出
- ✅ 基础数据清洗

## 🤝 贡献指南

欢迎提交Issue和Pull Request来改进这个项目！

### 开发环境设置
1. Fork本项目
2. 创建功能分支
3. 提交更改
4. 创建Pull Request

## 📄 许可证

本项目仅供学习和研究使用，请勿用于商业目的。

## 📞 联系方式

如有问题或建议，请通过Issue联系。

---

**免责声明**：本工具仅用于技术学习和研究目的，使用者需自行承担使用风险，并确保遵守相关法律法规和网站服务条款。